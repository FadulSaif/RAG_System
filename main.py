import os
import sys
import arabic_reshaper
from bidi.algorithm import get_display
from PDF_Extraction import extract_and_chunk_pdf 
from vector_storage import save_to_vector_store, search_vector_store
from api_client import get_arabert_embedding, generate_jais_response

def print_arabic(text):
    """Formats Arabic text to display correctly in Windows terminals"""
    reshaped_text = arabic_reshaper.reshape(text)
    bidi_text = get_display(reshaped_text)
    print(bidi_text)

def main():
    print("--- Seela RAG System Initializing ---")
    
    # 1. Setup paths for the Dataset folder
    pdf_files = [
        os.path.join("Dataset", "legal-guide-to-childs-rights-in-libya-arabic.pdf"),
        os.path.join("Dataset", "libyan_law.pdf")
    ]
    
    # 2. Extract and Chunk Text
    print("Step 1: Extracting text from Libyan Legal PDFs...")
    all_chunks = []
    for pdf in pdf_files:
        if os.path.exists(pdf):
            print(f"   -> Processing: {pdf}")
            # ADDED: Smaller chunk sizes to prevent the AraBERT 512-token limit crash
            chunks = extract_and_chunk_pdf(pdf, chunk_size=250, overlap=50)
            all_chunks.extend(chunks)
        else:
            print(f"Warning: {pdf} not found. Please check the 'Dataset' folder.")

    if not all_chunks:
        print("Error: No text was extracted. Check your PDF paths and try again.")
        return

    # 3. Generate Embeddings and Save to FAISS
    print(f"Step 2: Generating AraBERT embeddings for {len(all_chunks)} chunks...")
    print("   (Note: This may take up to a minute if the Hugging Face API is in 'Cold Start' mode)")
    
    all_embeddings = []
    for i, chunk in enumerate(all_chunks):
        embedding = get_arabert_embedding(chunk)
        all_embeddings.append(embedding)
        if (i + 1) % 5 == 0:
            print(f"   -> Progress: {i + 1}/{len(all_chunks)} chunks embedded...")

    print("Step 3: Indexing vectors in local FAISS store...")
    save_to_vector_store(all_embeddings, all_chunks)
    print("System Ready!!!")

    # 4. Run the Required Test Questions
    test_questions = [
        "Ù…Ø§ Ù‡ÙŠ Ø§Ù„Ù…Ø³Ø¤ÙˆÙ„ÙŠØ§Øª Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ© Ù„Ù„ÙˆØ²Ø§Ø±Ø§Øª ÙˆØ§Ù„Ø¬Ù‡Ø§Øª Ø§Ù„Ø­ÙƒÙˆÙ…ÙŠØ© ÙÙŠ Ù„ÙŠØ¨ÙŠØ§ ÙÙŠÙ…Ø§ ÙŠØ®Øµ Ø±Ø¹Ø§ÙŠØ© Ø§Ù„Ø£Ø·ÙØ§Ù„ØŸ",
        "Ù…Ø§ Ù‡ÙŠ Ø§Ù„Ø£Ø­ÙƒØ§Ù… Ø§Ù„Ù‚Ø§Ù†ÙˆÙ†ÙŠØ© Ø§Ù„Ù…ØªØ¹Ù„Ù‚Ø© Ø¨Ø§Ù„ÙˆØµØ§ÙŠØ© ÙˆØ§Ù„Ø­Ø¶Ø§Ù†Ø© ÙˆØ§Ù„Ù…Ø³Ø¤ÙˆÙ„ÙŠØ§Øª Ø§Ù„Ø£Ø¨ÙˆÙŠØ© ÙˆÙÙ‚Ø§ Ù„Ù„Ø¯Ù„ÙŠÙ„ØŸ",
        "Ù…Ø§ Ù‡ÙŠ Ø§Ù„Ù…Ø¹Ø§Ù‡Ø¯Ø§Øª Ø§Ù„Ø¯ÙˆÙ„ÙŠØ© Ø§Ù„Ù…ØªØ¹Ù„Ù‚Ø© Ø¨Ø­Ù‚ÙˆÙ‚ Ø§Ù„Ø·ÙÙ„ Ø§Ù„ØªÙŠ ØµØ§Ø¯Ù‚Øª Ø¹Ù„ÙŠÙ‡Ø§ Ù„ÙŠØ¨ÙŠØ§ØŸ",
        "ÙƒÙ… Ù‚ÙŠÙ…Ø© Ø±Ø£Ø³ Ù…Ø§Ù„ Ø§Ù„Ù…ØµØ±ÙØŸ",
        "Ù…Ø§ Ù‡ÙŠ Ø§Ù„Ù…Ø¤Ù‡Ù„Ø§Øª Ø§Ù„ØªØ¹Ù„ÙŠÙ…ÙŠØ© Ø§Ù„Ù…Ø´Ø±ÙˆØ·Ø© Ù„Ù„Ù…Ø¯ÙŠØ± Ø§Ù„Ø¹Ø§Ù… ÙˆÙ…Ø¬Ù„Ø³ Ø§Ù„Ø¥Ø¯Ø§Ø±Ø©ØŸ"
     ]

    print("\n" + "="*50)
    print("--- RUNNING EVALUATOR TEST QUESTIONS ---")
    print("="*50)

    for question in test_questions:
        print_arabic(f"\n[USER QUESTION]: {question}")
        
        q_vec = get_arabert_embedding(question)
        retrieved_chunks = search_vector_store(q_vec, top_k=3)
        context = "\n\n".join(retrieved_chunks)
        
        answer = generate_jais_response(context, question)
        
        print_arabic(f"[LLM ANSWER]: {answer}")

    # 5. Interactive Mode
    print("\n" + "="*50)
    print("--- ğŸ’¬ INTERACTIVE MODE (Type 'exit' or 'Click ctrl + C' to quit) ---")
    while True:
        user_input = input("\nAsk your own legal question: ")
        if user_input.lower() in ['exit', 'quit', 'Ø®Ø±ÙˆØ¬']:
            print("Shutting down. Good luck!")
            break
            
        if not user_input.strip(): continue

        q_vec = get_arabert_embedding(user_input)
        retrieved_chunks = search_vector_store(q_vec, top_k=3)
        context = "\n\n".join(retrieved_chunks)
        answer = generate_jais_response(context, user_input)
        
        print_arabic(f"\n[Answer]: {answer}")

if __name__ == "__main__":
    main()